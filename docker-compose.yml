services:
  neo4j-nginx:
    image: nginx:1.27
    container_name: neo4j-nginx
    restart: unless-stopped
    ports:
      - "8080:8080"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - neo4j-frontend
      - neo4j-backend
      - neo4j-browser
    networks:
      - shared-network

  neo4j-backend:
    build:
      context: ./llm-graph-builder/backend
      dockerfile: Dockerfile
    container_name: neo4j-backend
    restart: unless-stopped
    environment:
      - NEO4J_URI=${NEO4J_URI-neo4j://database:7687}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD-password}
      - NEO4J_USERNAME=${NEO4J_USERNAME-neo4j}
      - OPENAI_API_KEY=${OPENAI_API_KEY-}
      - DIFFBOT_API_KEY=${DIFFBOT_API_KEY-}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL-all-MiniLM-L6-v2}
      - LANGCHAIN_ENDPOINT=${LANGCHAIN_ENDPOINT-}
      - LANGCHAIN_TRACING_V2=${LANGCHAIN_TRACING_V2-}
      - LANGCHAIN_PROJECT=${LANGCHAIN_PROJECT-}
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY-}
      - KNN_MIN_SCORE=${KNN_MIN_SCORE-0.94}
      - IS_EMBEDDING=${IS_EMBEDDING-true}
      - GEMINI_ENABLED=${GEMINI_ENABLED-False}
      - GCP_LOG_METRICS_ENABLED=${GCP_LOG_METRICS_ENABLED-False}
      - UPDATE_GRAPH_CHUNKS_PROCESSED=${UPDATE_GRAPH_CHUNKS_PROCESSED-20}
      - NUMBER_OF_CHUNKS_TO_COMBINE=${NUMBER_OF_CHUNKS_TO_COMBINE-6}
      - ENTITY_EMBEDDING=${ENTITY_EMBEDDING-False}
      - GCS_FILE_CACHE=${GCS_FILE_CACHE-False}
      - LLM_MODEL_CONFIG_ollama_llama3=${LLM_MODEL_CONFIG_ollama_llama3-}
    volumes:
      - ./llm-graph-builder/backend:/code
      - ./models--sentence-transformers--all-MiniLM-L6-v2:/root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2
    networks:
      - shared-network

  neo4j-frontend:
    build:
      context: ./llm-graph-builder/frontend
      dockerfile: Dockerfile
      args:
        - VITE_BACKEND_API_URL=${VITE_BACKEND_API_URL-http://neo4j-backend:8000}
        - VITE_REACT_APP_SOURCES=${VITE_REACT_APP_SOURCES-local,wiki,s3}
        - VITE_GOOGLE_CLIENT_ID=${VITE_GOOGLE_CLIENT_ID-}
        - VITE_BLOOM_URL=${VITE_BLOOM_URL-https://workspace-preview.neo4j.io/workspace/explore?connectURL={CONNECT_URL}&search=Show+me+a+graph&featureGenAISuggestions=true&featureGenAISuggestionsInternal=true}
        - VITE_TIME_PER_PAGE=${VITE_TIME_PER_PAGE-50}
        - VITE_CHUNK_SIZE=${VITE_CHUNK_SIZE-5242880}
        - VITE_LARGE_FILE_SIZE=${VITE_LARGE_FILE_SIZE-5242880}
        - VITE_ENV=${VITE_ENV-DEV}
        - VITE_CHAT_MODES=${VITE_CHAT_MODES-}
        - VITE_BATCH_SIZE=${VITE_BATCH_SIZE-2}
        - VITE_LLM_MODELS=${VITE_LLM_MODELS-}
        - VITE_LLM_MODELS_PROD=${VITE_LLM_MODELS_PROD-openai_gpt_4o,openai_gpt_4o_mini,diffbot,gemini_1.5_flash}
    container_name: neo4j-frontend
    restart: unless-stopped
    environment:
      - VITE_BACKEND_API_URL=${VITE_BACKEND_API_URL-http://neo4j-backend:8000}
      - VITE_REACT_APP_SOURCES=${VITE_REACT_APP_SOURCES-local,wiki,s3}
      - VITE_GOOGLE_CLIENT_ID=${VITE_GOOGLE_CLIENT_ID-}
      - VITE_BLOOM_URL=${VITE_BLOOM_URL-https://workspace-preview.neo4j.io/workspace/explore?connectURL={CONNECT_URL}&search=Show+me+a+graph&featureGenAISuggestions=true&featureGenAISuggestionsInternal=true}
      - VITE_TIME_PER_PAGE=${VITE_TIME_PER_PAGE-50}
      - VITE_CHUNK_SIZE=${VITE_CHUNK_SIZE-5242880}
      - VITE_LARGE_FILE_SIZE=${VITE_LARGE_FILE_SIZE-5242880}
      - VITE_ENV=${VITE_ENV-DEV}
      - VITE_CHAT_MODES=${VITE_CHAT_MODES-}
      - VITE_BATCH_SIZE=${VITE_BATCH_SIZE-2}
      - VITE_LLM_MODELS=${VITE_LLM_MODELS-}
      - VITE_LLM_MODELS_PROD=${VITE_LLM_MODELS_PROD-openai_gpt_4o,openai_gpt_4o_mini,diffbot,gemini_1.5_flash}
    volumes:
      - ./llm-graph-builder/frontend:/app
    networks:
      - shared-network

  neo4j-browser:
    image: neo4j:5.26.5
    container_name: neo4j-browser
    restart: unless-stopped
    ports:
      - 7474:7474
      - 7687:7687
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD}
      - NEO4J_apoc_export_file_enabled=true
      - NEO4J_apoc_import_file_enabled=true
      - NEO4J_apoc_import_file_use__neo4j__config=true
      - NEO4J_PLUGINS=["apoc", "graph-data-science"]
    volumes:
      - ./neo4j_db/data:/data
      - ./neo4j_db/logs:/logs
      - ./neo4j_db/import:/var/lib/neo4j/import
      - ./neo4j_db/plugins:/plugins

  # vllm_qwen2.5:
  #   image: vllm/vllm-openai:v0.6.6
  #   container_name: vllm_qwen2.5
  #   restart: unless-stopped
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             device_ids: ['2']
  #             capabilities: [gpu]
  #   volumes:
  #     - ./models/qwen2.5-14b-coder-instruct:/models/
  #   networks:
  #     - shared-network
  #   ipc: host
  #   environment:
  #     - HF_HUB_OFFLINE=1
  #   command: [
  #     "--model", "/models/qwen2.5-14b-coder-instruct",
  #     "--served-model-name", "qwen2.5",
  #     "--trust-remote-code",
  #     "--guided-decoding-backend", "outlines",
  #     "--gpu-memory-utilization", "0.5"
  #   ]

  vllm_qwen2.5-placeholder:
    image: busybox
    container_name: vllm_qwen2.5
    restart: unless-stopped
    networks:
      - shared-network
    command: ["sh", "-c", "while true; do echo 'Service unavailable' | nc -l -p 8000; done"]

networks:
  shared-network:
    driver: bridge
